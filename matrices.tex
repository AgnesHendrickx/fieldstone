\subsection{Symmetric matrices}

Any {\sl symmetric} matrix 
has only real eigenvalues,
is always diagonalizable,
and has orthogonal eigenvectors.
A symmetric $N\times N$ real matrix ${\bm M}$ is said to be
\begin{itemize}
\item {\bf positive definite} if $\vec x \cdot {\bm M} \cdot \vec x >0$ for every non-zero vector $\vec x$ of n real numbers. All the eigenvalues of a  Symmetric Positive Definite (SPD) matrix are positive.
 If A and B are positive definite, then so is A+B.
The matrix inverse of a positive definite matrix is also positive definite.
An SPD matrix has a unique Cholesky decomposition. In other words the matrix ${\bm M}$ 
is positive definite if and only if there exists a unique
lower triangular matrix ${\bm L}$, with real and strictly positive diagonal elements, 
such that ${\bm M} = {\bm L}{\bm L}^T$
(the product of a lower triangular matrix and its conjugate transpose).
This factorization is called the Cholesky decomposition of ${\bm M}$.
\index{general}{Symmetric Positive Definite}

\item {\bf positive semi-definite} if $\vec x \cdot {\bm M} \cdot  \vec x \geq 0$
\item {\bf negative definite} if $\vec x \cdot {\bm M} \cdot \vec x < 0$
\item {\bf negative semi-definite} if $\vec x \cdot {\bm M} \cdot \vec x \leq 0$
\end{itemize}

The Stokes linear system
\[
\left( \begin{array}{cc}
\mathbb{K} & \mathbb{G}  \\ \mathbb{G}^T &  0
\end{array} \right) \cdot
\left( \begin{array}{c}  {\bm v} \\ {\bm p}  \end{array} \right) = 
\left( \begin{array}{c}  {\bm f} \\ {\bm g}  \end{array} \right) 
\]
is {\bf indefinite} (i.e. it has positive as well as negative eigenvalues).

A square matrix that is not invertible is called {\bf singular} or degenerate. A square matrix is singular if and only if its determinant is 0. Singular matrices are rare in the sense that if you pick a random square matrix, it will almost surely not be singular.

%--------------------------------
\subsection{Schur complement}

From wiki.
In linear algebra and the theory of matrices, the Schur complement of a matrix block (i.e., a submatrix within a larger matrix) is defined as follows.
Suppose ${\bm A}$, ${\bm B}$, ${\bm C}$, ${\bm D}$
are respectively $p\times p$, $p \times q$, $q \times p$ and $q \times q$ matrices, and $\mathbb{D}$ is invertible. Let
\[
{\bm M}=
\left( \begin{array}{cc}
{\bm A} & {\bm B}  \\ 
{\bm C} & {\bm D}
\end{array} \right) 
\]
so that ${\bm M}$ is a $(p+q)\times(p+q)$ matrix.
Then the Schur complement of the block ${\bm D}$ of the matrix ${\bm M}$ is the $p \times p$ matrix
\[
{\bm S}={\bm A}-{\bm B}\cdot {\bm D}^{-1}\cdot {\bm C}
\]
Application to solving linear equations: The Schur complement arises naturally 
in solving a system of linear equations such as
\begin{eqnarray}
{\bm A}\cdot\vec x+{\bm B}\cdot \vec y &=& \vec f \nonumber\\
{\bm C}\cdot\vec x+{\bm D}\cdot \vec y &=& \vec g \nonumber
\end{eqnarray}
where $\vec x$, $\vec f$ are $p$-dimensional vectors, $\vec y$, $\vec g$
are $q$-dimensional vectors,
and ${\bm A}$, ${\bm B}$, ${\bm C}$, ${\bm D}$ are as above.
Multiplying the bottom equation by ${\bm B}\cdot {\bm D}^{-1}$ 
and then subtracting from the top equation one obtains
\[
({\bm A}-{\bm B}\cdot {\bm D}^{-1}\cdot {\bm C})\cdot \vec x = \vec f - {\bm B}\cdot {\bm D}^{-1}\cdot \vec g
\]
Thus if one can invert ${\bm D}$ as well as the Schur complement of ${\bm D}$, one can solve for $\vec x$,
and then by using the equation $\bm C\cdot \vec x + \bm D \cdot \vec y = \vec g$ one can solve for $y$.
This reduces the problem of inverting a $(p+q) \times (p+q)$ matrix to that of inverting
a $p \times p$ matrix and a $q \times q$ matrix.
In practice one needs ${\bm D}$ to be well-conditioned in order for 
this algorithm to be numerically accurate.

Considering now the Stokes system: 
\[
\left( \begin{array}{cc}
\K & \G  \\ \G^T &  -\C
\end{array} \right) \cdot
\left( \begin{array}{c}  {\vec v} \\ {\vec p}  \end{array} \right) = 
\left( \begin{array}{c}  {\vec f} \\ {\vec g}  \end{array} \right) 
\]
Factorising for ${\vec p}$ we end up with a {\bf velocity-Schur complement}.
Solving for ${\vec p}$ in the second equation and inserting the expression
for ${\vec p}$ into the first equation we have
\[
\mathbb{S}_v \cdot {\vec v}  = {\vec f} 
\quad\quad
\text{with}
\quad\quad
\mathbb{S}_v=\K+ \G \cdot \C^{-1} \cdot \G^T
\]
Factorising for $\vec v$ we get a {\bf pressure-Schur complement}.
\[
\mathbb{S}_p \cdot {\vec p}  = \G^T \cdot \K^{-1}\cdot {\vec f}
\quad\quad
\text{with}
\quad\quad
\mathbb{S}_p = \G^T \cdot \K^{-1}\cdot \G + \C 
\]


